{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1ubmWI9V83LLZUCwsWX86YdDqmB69lueb","authorship_tag":"ABX9TyO7GZQ7kcH4xRBREvrrZO7Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","from tqdm import tqdm"],"metadata":{"id":"clvZQjXRNYnd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V8L8v09ENQ4X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694245506790,"user_tz":-330,"elapsed":5,"user":{"displayName":"PG 44 Hussain Rangwala","userId":"11783751594745638906"}},"outputId":"60a86c3d-fbca-4690-fc9d-8ce9add3780d"},"outputs":[{"output_type":"stream","name":"stdout","text":["TENSORFLOW VERSION:  2.13.0\n"]}],"source":["import tensorflow as tf\n","print(\"TENSORFLOW VERSION: \",tf.__version__)"]},{"cell_type":"markdown","source":["<br/>\n","<br/>\n","<br/>\n","\n","# LOADING DATA"],"metadata":{"id":"Wwr6FikpSbZF"}},{"cell_type":"code","source":["import json\n","def get_data(path):\n","  f = open(path)\n","  data = json.load(f)\n","  return data['amplitude'][:44100],data['label']\n","\n","def data_loader(path):\n","  amplitudes = []\n","  labels = []\n","  for file in tqdm(os.listdir(path)):\n","    amplitude,label = get_data(f'{path}/{file}')\n","    amplitudes.append(amplitude)\n","    labels.append(label)\n","\n","  return np.array(amplitudes),np.array(labels)"],"metadata":{"id":"-Rpdgp6INWgR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TRAIN_PATH =\"./drive/MyDrive/UrbanSoundDataset/train\"\n","VAL_PATH =\"./drive/MyDrive/UrbanSoundDataset/val\"\n","TEST_PATH =\"./drive/MyDrive/UrbanSoundDataset/test\"\n","\n","train_amp , train_labels = data_loader(TRAIN_PATH)\n","val_amp , val_labels = data_loader(VAL_PATH)\n","test_amp , test_labels = data_loader(TEST_PATH)"],"metadata":{"id":"I9_FkvmOO6QW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9e3a75ff-883a-43b1-e9c2-d2ee074c6646"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[" 83%|████████▎ | 5785/6985 [06:58<03:23,  5.88it/s]"]}]},{"cell_type":"code","source":["train_amp.shape"],"metadata":{"id":"mCCv961-X9C7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_amp.shape"],"metadata":{"id":"Uw-i1MK0X9AJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_amp.shape"],"metadata":{"id":"v2SqoYwsY5cJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<br/>\n","<br/>\n","\n","### LABEL ENCODING"],"metadata":{"id":"jzNzezKMS1R1"}},{"cell_type":"code","source":["unique_labels = pd.Series(train_labels).value_counts().index\n","NUM_OUTPUT_CLASSES = len(unique_labels)\n","unique_labels"],"metadata":{"id":"JDWUg-M9SyNs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","le.fit(train_labels)\n","\n","encoded_train_labels = le.transform(train_labels)\n","encoded_val_labels = le.transform(val_labels)\n","encoded_test_labels = le.transform(test_labels)"],"metadata":{"id":"mvoMOqXhSyK5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_train_labels.shape,encoded_val_labels.shape,encoded_test_labels.shape"],"metadata":{"id":"OiIhaHV_cwMa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<br/>\n","<br/>\n","<br/>\n","\n","### CREATING ANN"],"metadata":{"id":"fTnWTTPjT5Y-"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential,load_model\n","from tensorflow.keras.layers import Dense , BatchNormalization , Dropout , Flatten\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from IPython.display import clear_output"],"metadata":{"id":"KBU6s9rBdDIa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# If path does not exist then create the folder\n","if not os.path.isdir('./drive/MyDrive/UrbanSoundDataset/model_logs'):\n","    os.mkdir('./drive/MyDrive/UrbanSoundDataset/model_logs')"],"metadata":{"id":"8oM783dpvBW2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_loss_plots(train_loss,val_loss):\n","  plt.figure(figsize=(8,5),facecolor='#BCD9FC')\n","  ax = plt.axes()\n","  ax.set_facecolor(\"#BCD9FC\")\n","  ax.grid(color=\"white\")\n","\n","  plt.plot(train_loss,label=\"training loss\",color=\"green\",marker='x')\n","  plt.plot(val_loss,label=\"validation loss\",color=\"red\",marker='o')\n","  plt.title(\"Training Loss VS Validation Loss\")\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(\"Loss\")\n","\n","  plt.legend();\n","  plt.show();"],"metadata":{"id":"Jj4aAxZlieyQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_accuracy_plots(train_accuracy,val_accuracy):\n","  plt.figure(figsize=(8,5),facecolor='#BCD9FC')\n","  ax = plt.axes()\n","  ax.set_facecolor(\"#BCD9FC\")\n","  ax.grid(color=\"white\")\n","\n","  plt.plot(train_accuracy,label=\"training accuracy\",color=\"green\",marker='x')\n","  plt.plot(val_accuracy,label=\"validation accuracy\",color=\"red\",marker='o')\n","  plt.title(\"Training Acc VS Validation Acc\")\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(\"Accuracy\")\n","\n","  plt.legend();\n","  plt.show();"],"metadata":{"id":"Uh2W7ymKier9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_confusion_matrix(y_true,y_pred,title,target_names):\n","  cm = confusion_matrix(y_true, y_pred)\n","\n","  plt.figure(figsize=(7,7))\n","  sns.heatmap(data = cm,annot=True,cmap=\"coolwarm\",xticklabels=target_names, yticklabels=target_names)\n","  plt.title(title)\n","  plt.show();"],"metadata":{"id":"tg4GfOA2iem_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_model_summary(model,filename):\n","    # If path does not exist then create the folder\n","    if not os.path.isdir('./drive/MyDrive/UrbanSoundDataset/models'):\n","        os.mkdir('./drive/MyDrive/UrbanSoundDataset/models')\n","\n","    with open(f'./drive/MyDrive/UrbanSoundDataset/models/{filename}.txt','w') as f:\n","        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n","    print(\"MODEL SUMMARY SAVED\")\n","\n","def save_classification_report(report,filename):\n","    # If path does not exist then create the folder\n","    if not os.path.isdir('./drive/MyDrive/UrbanSoundDataset/reports'):\n","        os.mkdir('./drive/MyDrive/UrbanSoundDataset/reports')\n","\n","    with open(f'./drive/MyDrive/UrbanSoundDataset/reports/{filename}.txt','w') as f:\n","        print(report, file=f)\n","    print(\"REPORT SAVED\")"],"metadata":{"id":"oH30oRg6tERn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_and_test(model,filename):\n","\n","  model.compile( optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy() , metrics = ['accuracy'] )\n","  model_path = f\"./drive/MyDrive/UrbanSoundDataset/{filename}.h5\"\n","\n","  es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3,verbose=1)\n","  cl = tf.keras.callbacks.CSVLogger(f'./drive/MyDrive/UrbanSoundDataset/model_logs/{filename}.csv')\n","  mc = tf.keras.callbacks.ModelCheckpoint( filepath=model_path , save_weights_only=True , monitor='val_accuracy', mode='max', save_best_only=True , verbose=1 )\n","\n","\n","  history = model.fit( train_dataset , validation_data=val_dataset , epochs=1000 , callbacks=[es,cl,mc] , verbose=1)\n","\n","  # CLEARING THE OUTPUT\n","  clear_output()\n","\n","  # LOADING MODEL\n","  best_model = load_model(model_path)\n","\n","  # LOSS AND ACCURACY PLOTS\n","  target_names = le.inverse_transform([i for i in range(NUM_OUTPUT_CLASSES)])\n","  plot_loss_plots(history.history[\"loss\"],history.history[\"val_loss\"])\n","  plot_accuracy_plots(history.history[\"accuracy\"],history.history[\"val_accuracy\"])\n","\n","  test_loss, test_accuracy = best_model.evaluate(test_amp, encoded_test_labels)\n","  test_pred_labels = best_model.predict(test_amp).argmax(axis=1)\n","  val_pred_labels = best_model.predict(val_amp).argmax(axis=1)\n","  print()\n","  print(\"TESTING LOSS: \",test_loss)\n","  print(\"TESTING ACCURACY: \",test_accuracy)\n","  print()\n","\n","  # CONFUSION MATRICES\n","  plot_confusion_matrix(encoded_test_labels , test_pred_labels , \"Test Data Confusion Matrix\",target_names)\n","  plot_confusion_matrix(encoded_val_labels , val_pred_labels , \"Validation Data Confusion Matrix\",target_names)\n","\n","  # CLASSIFICATION REPORT\n","  report = classification_report( encoded_test_labels , test_pred_labels , target_names=target_names )\n","  print(report)\n","\n","  # SAVING MODEL SUMMARY AND CLASSIFICATION REPORT\n","  save_model_summary(model,filename)\n","  save_classification_report(report,filename)\n"],"metadata":{"id":"nCtJzOpMSyIN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential([\n","    Flatten(input_shape=(train_mfccs.shape[1],train_mfccs.shape[2])),\n","\n","    Dense(512,activation='relu'),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","\n","    Dense(256,activation='relu'),\n","    BatchNormalization(),\n","\n","    Dense(256,activation='relu'),\n","    BatchNormalization(),\n","\n","    Dense(64,activation='relu'),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","\n","    Dense(NUM_OUTPUT_CLASSES,activation='softmax')\n","])\n","model.summary()"],"metadata":{"id":"dhgbKnsaSyFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filename=f\"{model.name}\"\n","train_and_test(model,filename)"],"metadata":{"id":"WIVUN_Fl0Nu3"},"execution_count":null,"outputs":[]}]}